{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2c6107a5a046dac",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-09T02:53:55.768863912Z",
     "start_time": "2023-10-09T02:53:54.586157484Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from model import GPT, GPTConfig\n",
    "from context_free_grammar import CFG\n",
    "import wandb\n",
    "import lightning.pytorch as pl\n",
    "import pytorch_lightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1f46ae49-4b78-47ab-9e0b-b88dcad2b8f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33maboitrea\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "05ffd0ef-b258-4da3-bc4e-003b2874a415",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-09T02:11:40.499794928Z",
     "start_time": "2023-10-09T02:11:40.348680742Z"
    }
   },
   "outputs": [],
   "source": [
    "cfg = CFG(L=3, ns=[1, 3, 3, 10], nr=[2, 2, 2], T=[8, 8, 8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "099a5b58-a460-4803-a8dd-3969ea261e54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of parameters: 10.64M\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): GPT(\n",
       "    (transformer): ModuleDict(\n",
       "      (wte): Embedding(10, 384)\n",
       "      (wpe): Embedding(256, 384)\n",
       "      (drop): Dropout(p=0.0, inplace=False)\n",
       "      (h): ModuleList(\n",
       "        (0-5): 6 x Block(\n",
       "          (ln_1): LayerNorm()\n",
       "          (attn): MultiHeadAttention(\n",
       "            (heads): ModuleList(\n",
       "              (0-5): 6 x Head(\n",
       "                (key): Linear(in_features=384, out_features=64, bias=False)\n",
       "                (query): Linear(in_features=384, out_features=64, bias=False)\n",
       "                (value): Linear(in_features=384, out_features=64, bias=False)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ln_2): LayerNorm()\n",
       "          (mlp): MLP(\n",
       "            (c_fc): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (gelu): GELU(approximate='none')\n",
       "            (c_proj): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (ln_f): LayerNorm()\n",
       "    )\n",
       "    (lm_head): Linear(in_features=384, out_features=10, bias=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_length = np.prod(cfg.T)\n",
    "start = time.time()\n",
    "config = GPTConfig(vocab_size=cfg.ns[-1], n_embd=384, n_head=6, n_layer=6)\n",
    "m = GPT(config)\n",
    "m = nn.DataParallel(m)\n",
    "m.to(config.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "51508252-d263-4f81-8847-b6ae457a0f55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.742784 M parameters\n"
     ]
    }
   ],
   "source": [
    " # print the number of parameters in the model\n",
    "print(sum(p.numel() for p in m.parameters()) / 1e6, \"M parameters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d452081b-3a2a-4bcd-80d1-aca0246612e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data loading = sample new sentences to fill-in the mini-batch\n",
    "def get_batch(config: GPTConfig = GPTConfig()):\n",
    "    sentence = cfg.sample_flattened(1)[0][0].view(sentence_length)  # reshape in a 1d tensor\n",
    "    # generate a small batch of data of inputs x and targets y\n",
    "    ix = torch.randint(0, sentence_length - config.block_size, size=(config.batch_size,))\n",
    "    x = torch.stack([sentence[i: i + config.block_size] for i in ix])\n",
    "    y = torch.stack([sentence[i+1: i + config.block_size + 1] for i in ix])\n",
    "    x, y = x.to(config.device), y.to(config.device)\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "853bde6d-4131-46fc-82cf-4b17c049038f",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def estimate_loss(eval_iters):\n",
    "    # This function samples a new batch of sentences and evaluates the loss of the model\n",
    "    out = {}\n",
    "    m.eval()\n",
    "    losses = torch.zeros(eval_iters)\n",
    "    for k in range(eval_iters):\n",
    "        X, Y = get_batch()\n",
    "        logits = m(X)\n",
    "        loss = nn.functional.cross_entropy(logits.view(-1, logits.size(-1)), Y.view(-1), ignore_index=-1)\n",
    "        losses[k] = loss.item()\n",
    "    out[\"val\"] = losses.mean()\n",
    "    m.train()\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "13cc4b3e-cd5b-4a91-bd43-82de465984ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "context_length = 3\n",
    "@torch.no_grad()\n",
    "def estimate_grammar_err(n_gen=100):\n",
    "    m.eval()\n",
    "    model = m.module\n",
    "    # generate n_gen sentences from the model and check their correctness\n",
    "    # for generating sentences from the model, we first sample a real sentence from the grammar\n",
    "    # then, the model is given the first 'context_length' tokens and asked to complete the sentence\n",
    "    # Returns the number of sentence correct (with 0 mistake) at each level\n",
    "    error_per_sentence = []    \n",
    "    for i in range(n_gen):\n",
    "        mistakes = []\n",
    "        context = cfg.sample_flattened(1)[0][0][:,:context_length].to(config.device)\n",
    "        gen_sentence = m.module.generate(context.reshape(1,3), max_new_tokens=sentence_length-context_length)[0].view(-1,1)\n",
    "        _, err = cfg.collapse_and_get_err(gen_sentence.view(*cfg.T).cpu())\n",
    "        for level_errors in err:\n",
    "            mistakes.append(torch.count_nonzero(level_errors).detach().numpy())\n",
    "        error_per_sentence.append(np.array(mistakes))\n",
    "    error_per_sentence = np.array(error_per_sentence)\n",
    "    # compute number of sentence that are correct at each level of the grammar\n",
    "    res = []\n",
    "    for l in range(cfg.L):\n",
    "        nb_correct = (n_gen - np.count_nonzero(error_per_sentence[:,l]))\n",
    "        res.append(nb_correct)\n",
    "    m.train()\n",
    "    return np.array(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5f111d8f-2b28-4bdb-908b-edbb34e70150",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_parameters = {'max_iters' : 5000,\n",
    "                       'eval_interval' : 200,\n",
    "                       'eval_iters' : 50,\n",
    "                       'quality_metric_iters' : 40,\n",
    "                       'learning_rate' : 1e-3,\n",
    "                       'architecture':\"GPT 10.7M\",\n",
    "                       'grammar': cfg.__str__(),\n",
    "                       'batch_size':config.batch_size,}\n",
    "training_parameters['optimizer'] = torch.optim.AdamW(m.parameters(), lr=training_parameters['learning_rate'])\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(training_parameters['optimizer'], mode='min', patience=2, factor=0.1) # Divide lr by 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d352a020-b5cf-4996-9d4a-f9af56be809a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "def train(m):\n",
    "    for iter in range(training_parameters['max_iters']):\n",
    "        # every once in a while evaluate the loss on newly generated sentences\n",
    "        if iter % training_parameters['eval_interval'] == 0 or iter == training_parameters['max_iters'] - 1:\n",
    "            wandb.log({\"nb sentences seen\": iter*config.batch_size})\n",
    "            val_loss = estimate_loss(training_parameters['eval_iters'])['val']\n",
    "            print(\n",
    "                f\"step {iter}: val loss {val_loss:.4f}\"\n",
    "            )\n",
    "            wandb.log({\"loss\": val_loss})\n",
    "            scheduler.step(metrics=val_loss)\n",
    "            wandb.log({\"learning_rate\": training_parameters['optimizer'].param_groups[0][\"lr\"]})\n",
    "            \n",
    "            errors = estimate_grammar_err(training_parameters['quality_metric_iters'])\n",
    "            print(\n",
    "                f\"step {iter}: correct sentences for each level{errors}\"\n",
    "            )\n",
    "            for i, err in enumerate(errors):\n",
    "                wandb.log({f'% of correct sentences at level {i}': err/training_parameters['quality_metric_iters']})\n",
    "    \n",
    "        # sample a batch of data\n",
    "        xb, yb = get_batch()\n",
    "    \n",
    "        # evaluate the loss\n",
    "        logits = m(xb)\n",
    "        training_parameters['optimizer'].zero_grad(set_to_none=True)\n",
    "        loss = nn.functional.cross_entropy(logits.view(-1, logits.size(-1)), yb.view(-1), ignore_index=-1)\n",
    "        loss.backward()\n",
    "        training_parameters['optimizer'].step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "995d5739-902c-4a28-a12c-b06c35a66ff5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "wandb version 0.15.12 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/adrien/CFGProject/wandb/run-20231010_202509-ep0pik22</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/aboitrea/CFG-experiments/runs/ep0pik22' target=\"_blank\">zany-water-9</a></strong> to <a href='https://wandb.ai/aboitrea/CFG-experiments' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/aboitrea/CFG-experiments' target=\"_blank\">https://wandb.ai/aboitrea/CFG-experiments</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/aboitrea/CFG-experiments/runs/ep0pik22' target=\"_blank\">https://wandb.ai/aboitrea/CFG-experiments/runs/ep0pik22</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0: val loss 2.3648\n",
      "step 0: correct sentences for each level[0 0 0]\n",
      "step 200: val loss 1.4621\n",
      "step 200: correct sentences for each level[0 0 0]\n",
      "step 400: val loss 0.5664\n",
      "step 400: correct sentences for each level[0 0 0]\n",
      "step 600: val loss 0.2511\n",
      "step 600: correct sentences for each level[0 0 0]\n",
      "step 800: val loss 0.2331\n",
      "step 800: correct sentences for each level[0 0 0]\n",
      "step 1200: correct sentences for each level[0 0 1]\n",
      "step 1400: val loss 0.2102\n",
      "step 1400: correct sentences for each level[ 0  0 13]\n",
      "step 1600: val loss 0.2043\n",
      "step 1600: correct sentences for each level[ 0  0 23]\n",
      "step 1800: val loss 0.2020\n",
      "step 1800: correct sentences for each level[ 0  0 11]\n",
      "step 2000: val loss 0.2045\n"
     ]
    }
   ],
   "source": [
    "wandb.init(project='CFG-experiments',config=training_parameters)\n",
    "wandb.watch(m, log='all', log_freq=1)\n",
    "\n",
    "train(m)\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77d6c65a-d476-4243-98f6-fe2eb2159bb6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
