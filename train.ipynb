{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c2c6107a5a046dac",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-09T02:53:55.768863912Z",
     "start_time": "2023-10-09T02:53:54.586157484Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from model import GPT, GPTConfig\n",
    "from context_free_grammar import CFG\n",
    "import wandb\n",
    "import lightning.pytorch as pl\n",
    "import pytorch_lightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f46ae49-4b78-47ab-9e0b-b88dcad2b8f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33maboitrea\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "05ffd0ef-b258-4da3-bc4e-003b2874a415",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-09T02:11:40.499794928Z",
     "start_time": "2023-10-09T02:11:40.348680742Z"
    }
   },
   "outputs": [],
   "source": [
    "cfg = CFG(L=3, ns=[1, 3, 3, 10], nr=[2, 2, 2], T=[8, 8, 8])\n",
    "sentence_length = np.prod(cfg.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "099a5b58-a460-4803-a8dd-3969ea261e54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of parameters: 10.64M\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): GPT(\n",
       "    (transformer): ModuleDict(\n",
       "      (wte): Embedding(10, 384)\n",
       "      (wpe): Embedding(256, 384)\n",
       "      (drop): Dropout(p=0.0, inplace=False)\n",
       "      (h): ModuleList(\n",
       "        (0-5): 6 x Block(\n",
       "          (ln_1): LayerNorm()\n",
       "          (attn): MultiHeadAttention(\n",
       "            (heads): ModuleList(\n",
       "              (0-5): 6 x Head(\n",
       "                (key): Linear(in_features=384, out_features=64, bias=False)\n",
       "                (query): Linear(in_features=384, out_features=64, bias=False)\n",
       "                (value): Linear(in_features=384, out_features=64, bias=False)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ln_2): LayerNorm()\n",
       "          (mlp): MLP(\n",
       "            (c_fc): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (gelu): GELU(approximate='none')\n",
       "            (c_proj): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (ln_f): LayerNorm()\n",
       "    )\n",
       "    (lm_head): Linear(in_features=384, out_features=10, bias=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start = time.time()\n",
    "config = GPTConfig(vocab_size=cfg.ns[-1], n_embd=384, n_head=6, n_layer=6)\n",
    "m = GPT(config)\n",
    "m = nn.DataParallel(m)\n",
    "m.to(config.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "51508252-d263-4f81-8847-b6ae457a0f55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.742784 M parameters\n"
     ]
    }
   ],
   "source": [
    " # print the number of parameters in the model\n",
    "print(sum(p.numel() for p in m.parameters()) / 1e6, \"M parameters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d452081b-3a2a-4bcd-80d1-aca0246612e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data loading = sample new sentences to fill-in the mini-batch\n",
    "def get_batch(config: GPTConfig = GPTConfig()):\n",
    "    sentence = cfg.sample_flattened(1)[0][0].view(sentence_length)  # reshape in a 1d tensor\n",
    "    # generate a small batch of data of inputs x and targets y\n",
    "    ix = torch.randint(0, sentence_length - config.block_size, size=(config.batch_size,))\n",
    "    x = torch.stack([sentence[i: i + config.block_size] for i in ix])\n",
    "    y = torch.stack([sentence[i+1: i + config.block_size + 1] for i in ix])\n",
    "    x, y = x.to(config.device), y.to(config.device)\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "853bde6d-4131-46fc-82cf-4b17c049038f",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def estimate_loss(m, eval_iters):\n",
    "    # This function samples a new batch of sentences and evaluates the loss of the model\n",
    "    out = {}\n",
    "    m.eval()\n",
    "    losses = torch.zeros(eval_iters)\n",
    "    for k in range(eval_iters):\n",
    "        X, Y = get_batch()\n",
    "        logits = m(X)\n",
    "        loss = nn.functional.cross_entropy(logits.view(-1, logits.size(-1)), Y.view(-1), ignore_index=-1)\n",
    "        losses[k] = loss.item()\n",
    "    out[\"val\"] = losses.mean()\n",
    "    m.train()\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "13cc4b3e-cd5b-4a91-bd43-82de465984ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "context_length = 3\n",
    "@torch.no_grad()\n",
    "def estimate_grammar_err(m, n_gen=100):\n",
    "    m.eval()\n",
    "    model = m.module\n",
    "    # generate n_gen sentences from the model and check their correctness\n",
    "    # for generating sentences from the model, we first sample a real sentence from the grammar\n",
    "    # then, the model is given the first 'context_length' tokens and asked to complete the sentence\n",
    "    # Returns the number of sentence correct (with 0 mistake) at each level\n",
    "    error_per_sentence = []    \n",
    "    for i in range(n_gen):\n",
    "        mistakes = []\n",
    "        context = cfg.sample_flattened(1)[0][0][:,:context_length].to(config.device)\n",
    "        gen_sentence = m.module.generate(context.reshape(1,3), max_new_tokens=sentence_length-context_length)[0].view(-1,1)\n",
    "        _, err = cfg.collapse_and_get_err(gen_sentence.view(*cfg.T).cpu())\n",
    "        for level_errors in err:\n",
    "            mistakes.append(torch.count_nonzero(level_errors).detach().numpy())\n",
    "        error_per_sentence.append(np.array(mistakes))\n",
    "    error_per_sentence = np.array(error_per_sentence)\n",
    "    # compute number of sentence that are correct at each level of the grammar\n",
    "    res = []\n",
    "    for l in range(cfg.L):\n",
    "        nb_correct = (n_gen - np.count_nonzero(error_per_sentence[:,l]))\n",
    "        res.append(nb_correct)\n",
    "    m.train()\n",
    "    return np.array(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5f111d8f-2b28-4bdb-908b-edbb34e70150",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_parameters = {'max_iters' : 15000,\n",
    "                       'eval_interval' : 500,\n",
    "                       'eval_iters' : 50,\n",
    "                       'quality_metric_iters' : 50,\n",
    "                       'learning_rate' : 1e-3,\n",
    "                       'architecture':\"GPT 10.7M\",\n",
    "                       'grammar': cfg.__str__(),\n",
    "                       'batch_size':config.batch_size,}\n",
    "training_parameters['optimizer'] = torch.optim.AdamW(m.parameters(), lr=training_parameters['learning_rate'])\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(training_parameters['optimizer'], mode='min', patience=2, factor=0.1) # Divide lr by 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d352a020-b5cf-4996-9d4a-f9af56be809a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "def train(m):\n",
    "    for iter in range(training_parameters['max_iters']):\n",
    "        # every once in a while evaluate the loss on newly generated sentences\n",
    "        if iter % training_parameters['eval_interval'] == 0 or iter == training_parameters['max_iters'] - 1:\n",
    "            val_loss = estimate_loss(m, training_parameters['eval_iters'])['val']\n",
    "            print(\n",
    "                f\"step {iter}: val loss {val_loss:.4f}\"\n",
    "            )\n",
    "            scheduler.step(metrics=val_loss)\n",
    "            \n",
    "            errors = estimate_grammar_err(m, training_parameters['quality_metric_iters'])\n",
    "            print(\n",
    "                f\"step {iter}: correct sentences for each level{errors}\"\n",
    "            )\n",
    "            log_dict = {\"nb sentences seen\": iter*config.batch_size,\n",
    "                          \"loss\": val_loss,\n",
    "                          \"learning_rate\": training_parameters['optimizer'].param_groups[0][\"lr\"]}\n",
    "            for i,err in enumerate(errors):\n",
    "               log_dict[f'% of correct sentences at level {i}'] = err/training_parameters['quality_metric_iters']\n",
    "            wandb.log(log_dict)\n",
    "    \n",
    "        # sample a batch of data\n",
    "        xb, yb = get_batch()\n",
    "    \n",
    "        # evaluate the loss\n",
    "        logits = m(xb)\n",
    "        training_parameters['optimizer'].zero_grad(set_to_none=True)\n",
    "        loss = nn.functional.cross_entropy(logits.view(-1, logits.size(-1)), yb.view(-1), ignore_index=-1)\n",
    "        loss.backward()\n",
    "        training_parameters['optimizer'].step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "995d5739-902c-4a28-a12c-b06c35a66ff5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "wandb version 0.15.12 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/adrien/CFGProject/wandb/run-20231011_154132-mqra85x9</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/aboitrea/CFG-experiments/runs/mqra85x9' target=\"_blank\">sage-sponge-10</a></strong> to <a href='https://wandb.ai/aboitrea/CFG-experiments' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/aboitrea/CFG-experiments' target=\"_blank\">https://wandb.ai/aboitrea/CFG-experiments</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/aboitrea/CFG-experiments/runs/mqra85x9' target=\"_blank\">https://wandb.ai/aboitrea/CFG-experiments/runs/mqra85x9</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0: val loss 2.4564\n",
      "step 0: correct sentences for each level[0 0 0]\n",
      "step 500: val loss 0.4503\n",
      "step 500: correct sentences for each level[0 0 0]\n",
      "step 1000: val loss 0.2039\n",
      "step 1000: correct sentences for each level[ 0  0 10]\n",
      "step 1500: val loss 0.1848\n",
      "step 1500: correct sentences for each level[ 0  0 14]\n",
      "step 2000: val loss 0.1533\n",
      "step 2000: correct sentences for each level[ 0  0 18]\n",
      "step 2500: val loss 0.1441\n",
      "step 2500: correct sentences for each level[ 0  0 39]\n",
      "step 3000: val loss 0.1383\n",
      "step 3000: correct sentences for each level[ 0  0 17]\n",
      "step 3500: val loss 0.1402\n",
      "step 3500: correct sentences for each level[ 0  0 22]\n",
      "step 4000: val loss 0.1354\n",
      "step 4000: correct sentences for each level[ 0  1 39]\n",
      "step 4500: val loss 0.1329\n",
      "step 4500: correct sentences for each level[ 0  0 38]\n",
      "step 5000: val loss 0.1286\n",
      "step 5000: correct sentences for each level[ 0  4 40]\n",
      "step 5500: val loss 0.1253\n"
     ]
    }
   ],
   "source": [
    "wandb.init(project='CFG-experiments',config=training_parameters)\n",
    "wandb.watch(m, log='all', log_freq=1)\n",
    "\n",
    "train(m)\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2817172f-5e01-466d-a392-6f7d60986cee",
   "metadata": {},
   "source": [
    "# GPT 2 with 85M parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2cb6945b-8c9c-4e0e-bd0e-027910692183",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bd45e3fe-2e64-4fc1-bd90-5999e4b6d550",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of parameters: 85.04M\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): GPT(\n",
       "    (transformer): ModuleDict(\n",
       "      (wte): Embedding(10, 768)\n",
       "      (wpe): Embedding(256, 768)\n",
       "      (drop): Dropout(p=0.0, inplace=False)\n",
       "      (h): ModuleList(\n",
       "        (0-11): 12 x Block(\n",
       "          (ln_1): LayerNorm()\n",
       "          (attn): MultiHeadAttention(\n",
       "            (heads): ModuleList(\n",
       "              (0-11): 12 x Head(\n",
       "                (key): Linear(in_features=768, out_features=64, bias=False)\n",
       "                (query): Linear(in_features=768, out_features=64, bias=False)\n",
       "                (value): Linear(in_features=768, out_features=64, bias=False)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ln_2): LayerNorm()\n",
       "          (mlp): MLP(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): GELU(approximate='none')\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (ln_f): LayerNorm()\n",
       "    )\n",
       "    (lm_head): Linear(in_features=768, out_features=10, bias=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# New experiment with larger model and same grammar\n",
    "config = GPTConfig(vocab_size=cfg.ns[-1], n_embd=768, n_head=12, n_layer=12)\n",
    "m_large = GPT(config)\n",
    "m_large = nn.DataParallel(m_large)\n",
    "m_large.to(config.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "69c4dba9-e217-4ef8-acec-c5e618abf1a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85.23264 M parameters\n"
     ]
    }
   ],
   "source": [
    "print(sum(p.numel() for p in m_large.parameters()) / 1e6, \"M parameters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8ad48a15-7741-43c7-8327-577e08b6848e",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_parameters = {'max_iters' : 15000,\n",
    "                       'eval_interval' : 500,\n",
    "                       'eval_iters' : 50,\n",
    "                       'quality_metric_iters' : 50,\n",
    "                       'learning_rate' : 1e-4,\n",
    "                       'architecture':\"GPT 85.04M\",\n",
    "                       'grammar': cfg.__str__(),\n",
    "                       'batch_size':config.batch_size,}\n",
    "training_parameters['optimizer'] = torch.optim.AdamW(m_large.parameters(), lr=training_parameters['learning_rate'])\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(training_parameters['optimizer'], mode='min', patience=2, factor=0.1) # Divide lr by 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c85374e3-f2ba-4c4c-a74f-b3c5df24d338",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:x2n4ws6r) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f5035763d344f5ba10f99dd9eeb2ac5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.008 MB of 0.008 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">elated-wave-21</strong> at: <a href='https://wandb.ai/aboitrea/CFG-experiments/runs/x2n4ws6r' target=\"_blank\">https://wandb.ai/aboitrea/CFG-experiments/runs/x2n4ws6r</a><br/> View job at <a href='https://wandb.ai/aboitrea/CFG-experiments/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjEwNTI0MjU5Ng==/version_details/v13' target=\"_blank\">https://wandb.ai/aboitrea/CFG-experiments/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjEwNTI0MjU5Ng==/version_details/v13</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20231013_092229-x2n4ws6r/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:x2n4ws6r). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef7b4f5c23b6410e9fe173446ae92fb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011113957432098687, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.12 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/adrien/CFGProject/wandb/run-20231013_093342-9firm848</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/aboitrea/CFG-experiments/runs/9firm848' target=\"_blank\">eternal-dawn-22</a></strong> to <a href='https://wandb.ai/aboitrea/CFG-experiments' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/aboitrea/CFG-experiments' target=\"_blank\">https://wandb.ai/aboitrea/CFG-experiments</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/aboitrea/CFG-experiments/runs/9firm848' target=\"_blank\">https://wandb.ai/aboitrea/CFG-experiments/runs/9firm848</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0: val loss 2.3375\n",
      "step 0: correct sentences for each level[0 0 0]\n",
      "step 500: val loss 0.2701\n",
      "step 500: correct sentences for each level[0 0 0]\n",
      "step 1000: val loss 0.1835\n",
      "step 1000: correct sentences for each level[0 0 0]\n",
      "step 1500: val loss 0.1413\n",
      "step 1500: correct sentences for each level[ 0  0 31]\n",
      "step 2500: val loss 0.1309\n"
     ]
    }
   ],
   "source": [
    "wandb.init(project='CFG-experiments',config=training_parameters)\n",
    "wandb.watch(m_large, log='all', log_freq=1)\n",
    "\n",
    "train(m_large)\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e33d3b3-6c9d-49e1-bd80-1707fd234a52",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
