{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c2c6107a5a046dac",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-24T10:09:21.059398803Z",
     "start_time": "2023-10-24T10:09:18.053528077Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from model import GPT, GPTConfig, SentenceGenerator\n",
    "from context_free_grammar import CFG\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1f46ae49-4b78-47ab-9e0b-b88dcad2b8f5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-21T13:09:43.212307512Z",
     "start_time": "2023-10-21T13:09:43.064589543Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "05ffd0ef-b258-4da3-bc4e-003b2874a415",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-09T02:11:40.499794928Z",
     "start_time": "2023-10-09T02:11:40.348680742Z"
    }
   },
   "outputs": [],
   "source": [
    "cfg = CFG(L=3, ns=[1, 3, 9, 10], nr=[2, 2, 2], T=[8, 8, 8])\n",
    "sentence_length = np.prod(cfg.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "099a5b58-a460-4803-a8dd-3969ea261e54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of parameters: 10.64M\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): GPT(\n",
       "    (transformer): ModuleDict(\n",
       "      (wte): Embedding(10, 384)\n",
       "      (wpe): Embedding(256, 384)\n",
       "      (drop): Dropout(p=0.0, inplace=False)\n",
       "      (h): ModuleList(\n",
       "        (0-5): 6 x Block(\n",
       "          (ln_1): LayerNorm()\n",
       "          (attn): MultiHeadAttention(\n",
       "            (heads): ModuleList(\n",
       "              (0-5): 6 x Head(\n",
       "                (key): Linear(in_features=384, out_features=64, bias=False)\n",
       "                (query): Linear(in_features=384, out_features=64, bias=False)\n",
       "                (value): Linear(in_features=384, out_features=64, bias=False)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ln_2): LayerNorm()\n",
       "          (mlp): MLP(\n",
       "            (c_fc): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (gelu): GELU(approximate='none')\n",
       "            (c_proj): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (ln_f): LayerNorm()\n",
       "    )\n",
       "    (lm_head): Linear(in_features=384, out_features=10, bias=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = GPTConfig(vocab_size=cfg.ns[-1], n_embd=384, n_head=6, n_layer=6)\n",
    "m = GPT(config)\n",
    "m = nn.DataParallel(m)\n",
    "m.to(config.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "51508252-d263-4f81-8847-b6ae457a0f55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.742784 M parameters\n"
     ]
    }
   ],
   "source": [
    " # print the number of parameters in the model\n",
    "print(sum(p.numel() for p in m.parameters()) / 1e6, \"M parameters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d452081b-3a2a-4bcd-80d1-aca0246612e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data loading = sample new sentences to fill-in the mini-batch\n",
    "def get_batch(config: GPTConfig = GPTConfig()):\n",
    "    sentence = cfg.sample_flattened(1)[0][0].view(sentence_length)  # reshape in a 1d tensor\n",
    "    # generate a small batch of data of inputs x and targets y\n",
    "    ix = torch.randint(0, sentence_length - config.block_size, size=(config.batch_size,))\n",
    "    x = torch.stack([sentence[i: i + config.block_size] for i in ix])\n",
    "    y = torch.stack([sentence[i+1: i + config.block_size + 1] for i in ix])\n",
    "    x, y = x.to(config.device), y.to(config.device)\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "853bde6d-4131-46fc-82cf-4b17c049038f",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def estimate_loss(m, eval_iters):\n",
    "    # This function samples a new batch of sentences and evaluates the loss of the model\n",
    "    out = {}\n",
    "    m.eval()\n",
    "    losses = torch.zeros(eval_iters)\n",
    "    for k in range(eval_iters):\n",
    "        X, Y = get_batch()\n",
    "        logits = m(X)\n",
    "        loss = nn.functional.cross_entropy(logits.view(-1, logits.size(-1)), Y.view(-1), ignore_index=-1)\n",
    "        losses[k] = loss.item()\n",
    "    out[\"val\"] = losses.mean()\n",
    "    m.train()\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "13cc4b3e-cd5b-4a91-bd43-82de465984ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "context_length = 3\n",
    "@torch.no_grad()\n",
    "def estimate_grammar_err_multipleGPU(m, n_gen=25):\n",
    "    m.eval()\n",
    "    # generate n_gen sentences on each GPU from the model and check their correctness -> 4*n_gen generated in total\n",
    "    # for generating sentences from the model, we first sample a real sentence from the grammar\n",
    "    # then, the model is given the first 'context_length' tokens and asked to complete the sentence\n",
    "    # Returns the number of sentence correct (with 0 mistake) at each level\n",
    "    error_per_sentence = []    \n",
    "    for i in range(n_gen):\n",
    "        context = cfg.sample_flattened(1)[0][0][:,:context_length].expand(4,context_length).to(config.device)  \n",
    "        parallel_generator = nn.DataParallel(SentenceGenerator(m.module, context, max_new_tokens=sentence_length-3))\n",
    "        gen_sentences = parallel_generator()\n",
    "        for sentence in gen_sentences:\n",
    "            _, err = cfg.collapse_and_get_err(sentence.view(*cfg.T).cpu())\n",
    "            mistakes = []\n",
    "            for level_errors in err:\n",
    "                mistakes.append(torch.count_nonzero(level_errors).detach().numpy())\n",
    "            error_per_sentence.append(np.array(mistakes))\n",
    "    error_per_sentence = np.array(error_per_sentence)\n",
    "    # compute number of sentence that are correct at each level of the grammar\n",
    "    res = []\n",
    "    for l in range(cfg.L):\n",
    "        nb_correct = (4*n_gen - np.count_nonzero(error_per_sentence[:,l]))\n",
    "        res.append(nb_correct)\n",
    "    m.train()\n",
    "    return np.array(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a2fb0e64-f902-4f13-9012-c821af64abc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "context_length = 3\n",
    "@torch.no_grad()\n",
    "def estimate_grammar_err(m, n_gen=100):\n",
    "    start = time.time()\n",
    "    m.eval()\n",
    "    model = m.module\n",
    "    # generate n_gen sentences from the model and check their correctness\n",
    "    # for generating sentences from the model, we first sample a real sentence from the grammar\n",
    "    # then, the model is given the first 'context_length' tokens and asked to complete the sentence\n",
    "    # Returns the number of sentence correct (with 0 mistake) at each level\n",
    "    error_per_sentence = []    \n",
    "    for i in range(n_gen):\n",
    "        mistakes = []\n",
    "        context = cfg.sample_flattened(1)[0][0][:,:context_length].to(config.device)\n",
    "        gen_sentence = m.module.generate(context.reshape(1,context_length), max_new_tokens=sentence_length-context_length)[0].view(-1,1)\n",
    "        _, err = cfg.collapse_and_get_err(gen_sentence.view(*cfg.T).cpu())\n",
    "        for level_errors in err:\n",
    "            mistakes.append(torch.count_nonzero(level_errors).detach().numpy())\n",
    "        error_per_sentence.append(np.array(mistakes))\n",
    "    error_per_sentence = np.array(error_per_sentence)\n",
    "    # compute number of sentence that are correct at each level of the grammar\n",
    "    res = []\n",
    "    for l in range(cfg.L):\n",
    "        nb_correct = (n_gen*4 - np.count_nonzero(error_per_sentence[:,l]))\n",
    "        res.append(nb_correct)\n",
    "    m.train()\n",
    "    return np.array(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5f111d8f-2b28-4bdb-908b-edbb34e70150",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_parameters = {'num_epoch': 500, # large number as we don't know yet what time it will take\n",
    "                       'batches_per_epoch' : 40,\n",
    "                       'eval_iters' : 500,\n",
    "                       'quality_metric_iters' : 125, # 1000 sentences in total generated at each val step\n",
    "                       'learning_rate' : 1e-5,\n",
    "                       'architecture':\"GPT 10M\",\n",
    "                       'grammar': cfg.__str__(),\n",
    "                       'batch_size':config.batch_size,}\n",
    "training_parameters['optimizer'] = torch.optim.AdamW(m.parameters(), lr=training_parameters['learning_rate'])\n",
    "\n",
    "# start at 1e-5 and increase by 1e-5 every 5 epochs until 1e-4 is reached\n",
    "lambda_lr = lambda epoch: (epoch//5 + 1) if epoch < 50 else 10\n",
    "#scheduler = torch.optim.lr_scheduler.LambdaLR(training_parameters['optimizer'], lr_lambda=[lambda_lr])\n",
    "\n",
    "max_lr = 1e-3  # Maximum learning rate\n",
    "min_lr = 1e-6  # Minimum learning rate\n",
    "total_epochs = training_parameters['num_epoch'] # Total number of epochs\n",
    "div_factor = 1e2  # LR max / LR start\n",
    "final_div_factor = 1e3  # LR max / LR end\n",
    "scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
    "    training_parameters['optimizer'],\n",
    "    max_lr=max_lr,\n",
    "    total_steps=total_epochs,\n",
    "    pct_start=0.2,\n",
    "    div_factor=div_factor,\n",
    "    final_div_factor=final_div_factor\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d352a020-b5cf-4996-9d4a-f9af56be809a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "def train(m):\n",
    "    print(f'One epoch is {training_parameters[\"batches_per_epoch\"]} steps,\\\n",
    "    validation is run at the end of every epoch and metrics are averaged over {4*training_parameters[\"quality_metric_iters\"]} sentences')\n",
    "    print(f'Will run for {training_parameters[\"num_epoch\"]} epochs')\n",
    "    for epoch in range(training_parameters['num_epoch']):\n",
    "        train_losses = []\n",
    "        for iter in range(training_parameters['batches_per_epoch']):\n",
    "            # sample a batch of data\n",
    "            xb, yb = get_batch()\n",
    "            # evaluate the loss\n",
    "            logits = m(xb)\n",
    "            training_parameters['optimizer'].zero_grad(set_to_none=True)\n",
    "            loss = nn.functional.cross_entropy(logits.view(-1, logits.size(-1)), yb.view(-1), ignore_index=-1)\n",
    "            train_losses.append(loss.item())\n",
    "            loss.backward()\n",
    "            training_parameters['optimizer'].step()\n",
    "        # evaluate the loss on newly generated sentences at the end of every epoch\n",
    "        if epoch % 50 == 0:\n",
    "            val_loss = estimate_loss(m, training_parameters[\"eval_iters\"])['val']\n",
    "            print(\n",
    "                f'epoch {epoch}: val loss {val_loss:.4f}'\n",
    "            )\n",
    "            \n",
    "            errors = estimate_grammar_err_multipleGPU(m, training_parameters['quality_metric_iters'])\n",
    "            print(\n",
    "                f'epoch {epoch}: correct sentences for each level{errors}'\n",
    "            )\n",
    "            log_dict = {\"nb sentences seen\": epoch*training_parameters['batches_per_epoch']*config.batch_size,\n",
    "                        \"loss\": val_loss,\n",
    "                        \"learning_rate\": training_parameters['optimizer'].param_groups[0][\"lr\"]}\n",
    "            for i,err in enumerate(errors):\n",
    "               log_dict[f'% of correct sentences at level {i}'] = err/(4*training_parameters['quality_metric_iters']) * 100\n",
    "            wandb.log(log_dict)\n",
    "        scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "995d5739-902c-4a28-a12c-b06c35a66ff5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:tjmk77ss) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53757df0d57948b98df36a72da15b06c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.008 MB of 0.008 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>% of correct sentences at level 0</td><td>▁▁▁▁▁█▁▁</td></tr><tr><td>% of correct sentences at level 1</td><td>▁▁▁▁▁▁▁▁</td></tr><tr><td>% of correct sentences at level 2</td><td>▁▁▁▁▁▁▁▁</td></tr><tr><td>learning_rate</td><td>▁▁▂▂▃▅▆█</td></tr><tr><td>loss</td><td>█▇▄▃▃▂▂▁</td></tr><tr><td>nb sentences seen</td><td>▁▂▃▄▅▆▇█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>% of correct sentences at level 0</td><td>0.0</td></tr><tr><td>% of correct sentences at level 1</td><td>0.0</td></tr><tr><td>% of correct sentences at level 2</td><td>0.0</td></tr><tr><td>learning_rate</td><td>6e-05</td></tr><tr><td>loss</td><td>1.88547</td></tr><tr><td>nb sentences seen</td><td>71680</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GPT 10M</strong> at: <a href='https://wandb.ai/aboitrea/CFG-experiments/runs/tjmk77ss' target=\"_blank\">https://wandb.ai/aboitrea/CFG-experiments/runs/tjmk77ss</a><br/> View job at <a href='https://wandb.ai/aboitrea/CFG-experiments/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjEwNTI0MjU5Ng==/version_details/v25' target=\"_blank\">https://wandb.ai/aboitrea/CFG-experiments/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjEwNTI0MjU5Ng==/version_details/v25</a><br/>Synced 5 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20231030_195604-tjmk77ss/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:tjmk77ss). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16f405147aa64b95b041af419008646e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01111361775547266, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.12 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/adrien/CFGProject/wandb/run-20231030_213110-w544it28</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/aboitrea/CFG-experiments/runs/w544it28' target=\"_blank\">GPT 10M</a></strong> to <a href='https://wandb.ai/aboitrea/CFG-experiments' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/aboitrea/CFG-experiments' target=\"_blank\">https://wandb.ai/aboitrea/CFG-experiments</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/aboitrea/CFG-experiments/runs/w544it28' target=\"_blank\">https://wandb.ai/aboitrea/CFG-experiments/runs/w544it28</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One epoch is 40 steps,    validation is run at the end of every epoch and metrics are averaged over 125 sentences\n",
      "Will run for 500 epochs\n",
      "epoch 0: val loss 1.7920\n"
     ]
    }
   ],
   "source": [
    "wandb.init(project='CFG-experiments',config=training_parameters, name='GPT 10M')\n",
    "wandb.watch(m, log='all')\n",
    "\n",
    "train(m)\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2817172f-5e01-466d-a392-6f7d60986cee",
   "metadata": {},
   "source": [
    "# GPT 2 with 85M parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb6945b-8c9c-4e0e-bd0e-027910692183",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd45e3fe-2e64-4fc1-bd90-5999e4b6d550",
   "metadata": {},
   "outputs": [],
   "source": [
    "# New experiment with larger model and same grammar\n",
    "config = GPTConfig(vocab_size=cfg.ns[-1], n_embd=768, n_head=12, n_layer=12)\n",
    "m_large = GPT(config)\n",
    "m_large = nn.DataParallel(m_large)\n",
    "m_large.to(config.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c4dba9-e217-4ef8-acec-c5e618abf1a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sum(p.numel() for p in m_large.parameters()) / 1e6, \"M parameters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad48a15-7741-43c7-8327-577e08b6848e",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_parameters = {'max_iters' : 15000,\n",
    "                       'eval_interval' : 500,\n",
    "                       'eval_iters' : 50,\n",
    "                       'quality_metric_iters' : 50,\n",
    "                       'learning_rate' : 1e-4,\n",
    "                       'architecture':\"GPT 85.04M\",\n",
    "                       'grammar': cfg.__str__(),\n",
    "                       'batch_size':config.batch_size,}\n",
    "training_parameters['optimizer'] = torch.optim.AdamW(m_large.parameters(), lr=training_parameters['learning_rate'])\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(training_parameters['optimizer'], mode='min', patience=2, factor=0.1) # Divide lr by 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c85374e3-f2ba-4c4c-a74f-b3c5df24d338",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "wandb.init(project='CFG-experiments',config=training_parameters)\n",
    "wandb.watch(m_large, log='all', log_freq=1)\n",
    "\n",
    "train(m_large)\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e33d3b3-6c9d-49e1-bd80-1707fd234a52",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
