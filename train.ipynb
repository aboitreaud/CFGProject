{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c2c6107a5a046dac",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-05T03:59:40.284415716Z"
    },
    "collapsed": false,
    "is_executing": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from model import GPT, GPTConfig\n",
    "from context_free_grammar import CFG\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f46ae49-4b78-47ab-9e0b-b88dcad2b8f5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-02T05:37:05.885231370Z",
     "start_time": "2023-11-02T05:37:05.737058587Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33maboitrea\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dd5e937-5b2c-482b-81cd-c803c2d3566c",
   "metadata": {},
   "source": [
    "### Define Context-Free grammar and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "05ffd0ef-b258-4da3-bc4e-003b2874a415",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-03T08:03:10.872172956Z",
     "start_time": "2023-11-03T08:03:10.850554826Z"
    }
   },
   "outputs": [],
   "source": [
    "cfg = CFG(L=3, ns=[1, 3, 9, 10], nr=[2, 2, 2], T=[8, 8, 8])\n",
    "sentence_length = np.prod(cfg.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "099a5b58-a460-4803-a8dd-3969ea261e54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of parameters: 10.63M\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): GPT(\n",
       "    (transformer): ModuleDict(\n",
       "      (wte): Embedding(10, 384)\n",
       "      (wpe): Embedding(511, 384)\n",
       "      (drop): Dropout(p=0.0, inplace=False)\n",
       "      (h): ModuleList(\n",
       "        (0): Block(\n",
       "          (ln_1): LayerNorm()\n",
       "          (attn): MultiHeadAttention(\n",
       "            (heads): ModuleList(\n",
       "              (0): Head(\n",
       "                (key): Linear(in_features=384, out_features=64, bias=False)\n",
       "                (query): Linear(in_features=384, out_features=64, bias=False)\n",
       "                (value): Linear(in_features=384, out_features=64, bias=False)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (1): Head(\n",
       "                (key): Linear(in_features=384, out_features=64, bias=False)\n",
       "                (query): Linear(in_features=384, out_features=64, bias=False)\n",
       "                (value): Linear(in_features=384, out_features=64, bias=False)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (2): Head(\n",
       "                (key): Linear(in_features=384, out_features=64, bias=False)\n",
       "                (query): Linear(in_features=384, out_features=64, bias=False)\n",
       "                (value): Linear(in_features=384, out_features=64, bias=False)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (3): Head(\n",
       "                (key): Linear(in_features=384, out_features=64, bias=False)\n",
       "                (query): Linear(in_features=384, out_features=64, bias=False)\n",
       "                (value): Linear(in_features=384, out_features=64, bias=False)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (4): Head(\n",
       "                (key): Linear(in_features=384, out_features=64, bias=False)\n",
       "                (query): Linear(in_features=384, out_features=64, bias=False)\n",
       "                (value): Linear(in_features=384, out_features=64, bias=False)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (5): Head(\n",
       "                (key): Linear(in_features=384, out_features=64, bias=False)\n",
       "                (query): Linear(in_features=384, out_features=64, bias=False)\n",
       "                (value): Linear(in_features=384, out_features=64, bias=False)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ln_2): LayerNorm()\n",
       "          (mlp): MLP(\n",
       "            (c_fc): Linear(in_features=384, out_features=1536, bias=False)\n",
       "            (gelu): GELU(approximate='none')\n",
       "            (c_proj): Linear(in_features=1536, out_features=384, bias=False)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): Block(\n",
       "          (ln_1): LayerNorm()\n",
       "          (attn): MultiHeadAttention(\n",
       "            (heads): ModuleList(\n",
       "              (0): Head(\n",
       "                (key): Linear(in_features=384, out_features=64, bias=False)\n",
       "                (query): Linear(in_features=384, out_features=64, bias=False)\n",
       "                (value): Linear(in_features=384, out_features=64, bias=False)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (1): Head(\n",
       "                (key): Linear(in_features=384, out_features=64, bias=False)\n",
       "                (query): Linear(in_features=384, out_features=64, bias=False)\n",
       "                (value): Linear(in_features=384, out_features=64, bias=False)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (2): Head(\n",
       "                (key): Linear(in_features=384, out_features=64, bias=False)\n",
       "                (query): Linear(in_features=384, out_features=64, bias=False)\n",
       "                (value): Linear(in_features=384, out_features=64, bias=False)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (3): Head(\n",
       "                (key): Linear(in_features=384, out_features=64, bias=False)\n",
       "                (query): Linear(in_features=384, out_features=64, bias=False)\n",
       "                (value): Linear(in_features=384, out_features=64, bias=False)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (4): Head(\n",
       "                (key): Linear(in_features=384, out_features=64, bias=False)\n",
       "                (query): Linear(in_features=384, out_features=64, bias=False)\n",
       "                (value): Linear(in_features=384, out_features=64, bias=False)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (5): Head(\n",
       "                (key): Linear(in_features=384, out_features=64, bias=False)\n",
       "                (query): Linear(in_features=384, out_features=64, bias=False)\n",
       "                (value): Linear(in_features=384, out_features=64, bias=False)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ln_2): LayerNorm()\n",
       "          (mlp): MLP(\n",
       "            (c_fc): Linear(in_features=384, out_features=1536, bias=False)\n",
       "            (gelu): GELU(approximate='none')\n",
       "            (c_proj): Linear(in_features=1536, out_features=384, bias=False)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): Block(\n",
       "          (ln_1): LayerNorm()\n",
       "          (attn): MultiHeadAttention(\n",
       "            (heads): ModuleList(\n",
       "              (0): Head(\n",
       "                (key): Linear(in_features=384, out_features=64, bias=False)\n",
       "                (query): Linear(in_features=384, out_features=64, bias=False)\n",
       "                (value): Linear(in_features=384, out_features=64, bias=False)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (1): Head(\n",
       "                (key): Linear(in_features=384, out_features=64, bias=False)\n",
       "                (query): Linear(in_features=384, out_features=64, bias=False)\n",
       "                (value): Linear(in_features=384, out_features=64, bias=False)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (2): Head(\n",
       "                (key): Linear(in_features=384, out_features=64, bias=False)\n",
       "                (query): Linear(in_features=384, out_features=64, bias=False)\n",
       "                (value): Linear(in_features=384, out_features=64, bias=False)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (3): Head(\n",
       "                (key): Linear(in_features=384, out_features=64, bias=False)\n",
       "                (query): Linear(in_features=384, out_features=64, bias=False)\n",
       "                (value): Linear(in_features=384, out_features=64, bias=False)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (4): Head(\n",
       "                (key): Linear(in_features=384, out_features=64, bias=False)\n",
       "                (query): Linear(in_features=384, out_features=64, bias=False)\n",
       "                (value): Linear(in_features=384, out_features=64, bias=False)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (5): Head(\n",
       "                (key): Linear(in_features=384, out_features=64, bias=False)\n",
       "                (query): Linear(in_features=384, out_features=64, bias=False)\n",
       "                (value): Linear(in_features=384, out_features=64, bias=False)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ln_2): LayerNorm()\n",
       "          (mlp): MLP(\n",
       "            (c_fc): Linear(in_features=384, out_features=1536, bias=False)\n",
       "            (gelu): GELU(approximate='none')\n",
       "            (c_proj): Linear(in_features=1536, out_features=384, bias=False)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): Block(\n",
       "          (ln_1): LayerNorm()\n",
       "          (attn): MultiHeadAttention(\n",
       "            (heads): ModuleList(\n",
       "              (0): Head(\n",
       "                (key): Linear(in_features=384, out_features=64, bias=False)\n",
       "                (query): Linear(in_features=384, out_features=64, bias=False)\n",
       "                (value): Linear(in_features=384, out_features=64, bias=False)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (1): Head(\n",
       "                (key): Linear(in_features=384, out_features=64, bias=False)\n",
       "                (query): Linear(in_features=384, out_features=64, bias=False)\n",
       "                (value): Linear(in_features=384, out_features=64, bias=False)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (2): Head(\n",
       "                (key): Linear(in_features=384, out_features=64, bias=False)\n",
       "                (query): Linear(in_features=384, out_features=64, bias=False)\n",
       "                (value): Linear(in_features=384, out_features=64, bias=False)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (3): Head(\n",
       "                (key): Linear(in_features=384, out_features=64, bias=False)\n",
       "                (query): Linear(in_features=384, out_features=64, bias=False)\n",
       "                (value): Linear(in_features=384, out_features=64, bias=False)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (4): Head(\n",
       "                (key): Linear(in_features=384, out_features=64, bias=False)\n",
       "                (query): Linear(in_features=384, out_features=64, bias=False)\n",
       "                (value): Linear(in_features=384, out_features=64, bias=False)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (5): Head(\n",
       "                (key): Linear(in_features=384, out_features=64, bias=False)\n",
       "                (query): Linear(in_features=384, out_features=64, bias=False)\n",
       "                (value): Linear(in_features=384, out_features=64, bias=False)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ln_2): LayerNorm()\n",
       "          (mlp): MLP(\n",
       "            (c_fc): Linear(in_features=384, out_features=1536, bias=False)\n",
       "            (gelu): GELU(approximate='none')\n",
       "            (c_proj): Linear(in_features=1536, out_features=384, bias=False)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): Block(\n",
       "          (ln_1): LayerNorm()\n",
       "          (attn): MultiHeadAttention(\n",
       "            (heads): ModuleList(\n",
       "              (0): Head(\n",
       "                (key): Linear(in_features=384, out_features=64, bias=False)\n",
       "                (query): Linear(in_features=384, out_features=64, bias=False)\n",
       "                (value): Linear(in_features=384, out_features=64, bias=False)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (1): Head(\n",
       "                (key): Linear(in_features=384, out_features=64, bias=False)\n",
       "                (query): Linear(in_features=384, out_features=64, bias=False)\n",
       "                (value): Linear(in_features=384, out_features=64, bias=False)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (2): Head(\n",
       "                (key): Linear(in_features=384, out_features=64, bias=False)\n",
       "                (query): Linear(in_features=384, out_features=64, bias=False)\n",
       "                (value): Linear(in_features=384, out_features=64, bias=False)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (3): Head(\n",
       "                (key): Linear(in_features=384, out_features=64, bias=False)\n",
       "                (query): Linear(in_features=384, out_features=64, bias=False)\n",
       "                (value): Linear(in_features=384, out_features=64, bias=False)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (4): Head(\n",
       "                (key): Linear(in_features=384, out_features=64, bias=False)\n",
       "                (query): Linear(in_features=384, out_features=64, bias=False)\n",
       "                (value): Linear(in_features=384, out_features=64, bias=False)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (5): Head(\n",
       "                (key): Linear(in_features=384, out_features=64, bias=False)\n",
       "                (query): Linear(in_features=384, out_features=64, bias=False)\n",
       "                (value): Linear(in_features=384, out_features=64, bias=False)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ln_2): LayerNorm()\n",
       "          (mlp): MLP(\n",
       "            (c_fc): Linear(in_features=384, out_features=1536, bias=False)\n",
       "            (gelu): GELU(approximate='none')\n",
       "            (c_proj): Linear(in_features=1536, out_features=384, bias=False)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): Block(\n",
       "          (ln_1): LayerNorm()\n",
       "          (attn): MultiHeadAttention(\n",
       "            (heads): ModuleList(\n",
       "              (0): Head(\n",
       "                (key): Linear(in_features=384, out_features=64, bias=False)\n",
       "                (query): Linear(in_features=384, out_features=64, bias=False)\n",
       "                (value): Linear(in_features=384, out_features=64, bias=False)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (1): Head(\n",
       "                (key): Linear(in_features=384, out_features=64, bias=False)\n",
       "                (query): Linear(in_features=384, out_features=64, bias=False)\n",
       "                (value): Linear(in_features=384, out_features=64, bias=False)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (2): Head(\n",
       "                (key): Linear(in_features=384, out_features=64, bias=False)\n",
       "                (query): Linear(in_features=384, out_features=64, bias=False)\n",
       "                (value): Linear(in_features=384, out_features=64, bias=False)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (3): Head(\n",
       "                (key): Linear(in_features=384, out_features=64, bias=False)\n",
       "                (query): Linear(in_features=384, out_features=64, bias=False)\n",
       "                (value): Linear(in_features=384, out_features=64, bias=False)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (4): Head(\n",
       "                (key): Linear(in_features=384, out_features=64, bias=False)\n",
       "                (query): Linear(in_features=384, out_features=64, bias=False)\n",
       "                (value): Linear(in_features=384, out_features=64, bias=False)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (5): Head(\n",
       "                (key): Linear(in_features=384, out_features=64, bias=False)\n",
       "                (query): Linear(in_features=384, out_features=64, bias=False)\n",
       "                (value): Linear(in_features=384, out_features=64, bias=False)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ln_2): LayerNorm()\n",
       "          (mlp): MLP(\n",
       "            (c_fc): Linear(in_features=384, out_features=1536, bias=False)\n",
       "            (gelu): GELU(approximate='none')\n",
       "            (c_proj): Linear(in_features=1536, out_features=384, bias=False)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (ln_f): LayerNorm()\n",
       "    )\n",
       "    (lm_head): Linear(in_features=384, out_features=10, bias=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = GPTConfig(vocab_size=cfg.ns[-1],\n",
    "                   block_size=sentence_length-1,\n",
    "                   n_embd=384, n_head=6,\n",
    "                   n_layer=6,\n",
    "                   batch_size=100)\n",
    "m = GPT(config)\n",
    "m = nn.DataParallel(m)\n",
    "m.to(config.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "51508252-d263-4f81-8847-b6ae457a0f55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.824192 M parameters\n"
     ]
    }
   ],
   "source": [
    " # print the number of parameters in the model\n",
    "million_params = sum(p.numel() for p in m.parameters()) / 1e6\n",
    "print(million_params, \"M parameters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b764eef5-f30b-4082-bc06-bae923d26a03",
   "metadata": {},
   "source": [
    "### Define some useful functions for training/validation steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d452081b-3a2a-4bcd-80d1-aca0246612e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data loading = sample new sentences to fill-in the mini-batch\n",
    "def get_batch(config: GPTConfig = GPTConfig()):\n",
    "    data, _ = cfg.sample(config.batch_size) # wasting labels (useless for the task)\n",
    "    N = data.shape[0] # should be equal to config.batch_size\n",
    "    data = data.view(N,sentence_length) # flatten them out to be (N,sentence_length)# reshape in a 1d tensor\n",
    "    # generate a batch of data of inputs x and targets y\n",
    "    x = data[:, 0:sentence_length-1]               # (bsz,sentence_length-1)\n",
    "    y = data[:, 1:sentence_length].contiguous()    # (bsz,sentence_length-1)\n",
    "    x, y = x.to(config.device), y.to(config.device)\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "853bde6d-4131-46fc-82cf-4b17c049038f",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def estimate_loss(m, eval_iters=100):\n",
    "    # This validation function samples a new batch of sentences and evaluates the loss of the model\n",
    "    # Takes 20s for 100 sentences\n",
    "    m.eval()\n",
    "    losses = torch.zeros(eval_iters)\n",
    "    for k in range(eval_iters):\n",
    "        X, Y = get_batch()\n",
    "        logits = m(X)\n",
    "        loss = nn.functional.cross_entropy(logits.view(-1, logits.size(-1)), Y.view(-1), ignore_index=-1)\n",
    "        losses[k] = loss.item()\n",
    "    return losses.mean().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a29c9235-0fa6-4baa-bf50-67bcbd583eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def eval_errors(m, n_gen=100, context_length=3):\n",
    "    # for generating sentences from the model, we first sample real sentences from the grammar\n",
    "    # then, the model is given the first 'context_length' symbols and asked to complete the sentence\n",
    "    # Takes 40s for 100 sentences\n",
    "    if isinstance(m, nn.DataParallel):\n",
    "        m = m.module\n",
    "    \n",
    "    m.eval()\n",
    "    context = cfg.sample(n_gen)[0].view(n_gen, sentence_length)[:,:context_length].to(config.device)\n",
    "    gen_sentences = m.generate(context, max_new_tokens= sentence_length - context_length, temperature=0.1)\n",
    "\n",
    "    # compute accuracy \n",
    "    gen_sentences = gen_sentences.view([n_gen] +  cfg.T).cpu()\n",
    "    acc = cfg.frac_of_gramatically_correct_sentences(gen_sentences)  \n",
    "    \n",
    "    # compute per-level errors\n",
    "    # a sentence can only be good at level i if it was good at all levels beteewn L and i+1\n",
    "    correct_sentences = np.zeros(cfg.L)\n",
    "    for sentence in gen_sentences:\n",
    "        _, err = cfg.collapse_and_get_err(sentence)\n",
    "        \n",
    "        for i in range(len(err)-1,-1, -1):\n",
    "            if err[i].sum() != 0:\n",
    "                break\n",
    "            else:\n",
    "                correct_sentences[i] += 1\n",
    "                \n",
    "    return acc, np.array(correct_sentences) / n_gen * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92c277c0-dbd4-452b-ade3-ef15d69ef908",
   "metadata": {},
   "source": [
    "### Learning rate scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "87f10904-40ed-4d6f-bf87-3fb5a63f9e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lr(i,i_final):\n",
    "    coeff = 0.5 * (1.0 + math.cos(math.pi * i/i_final)) # decays from 1 to 0 \n",
    "    return min_lr + coeff * (max_lr - min_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b287f600-131d-4e5c-925c-51b93a53a59d",
   "metadata": {},
   "source": [
    "### Training parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d647d6ae-3db2-456a-a3f5-37fc2ddf4417",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num decayed parameter tensors: 128, with 10,816,896 parameters\n",
      "num non-decayed parameter tensors: 19, with 7,296 parameters\n"
     ]
    }
   ],
   "source": [
    "# adamw optimizer\n",
    "max_lr = 6e-4 # max learning rate\n",
    "min_lr = max_lr/10\n",
    "decay_lr = True\n",
    "\n",
    "weight_decay = 1e-1\n",
    "beta1 = 0.9\n",
    "beta2 = 0.95\n",
    "grad_clip = 1.0 # clip gradients at this value, or disable if == 0.0\n",
    "\n",
    "optimizer = m.module.configure_optimizers(weight_decay, max_lr, (beta1, beta2), device_type='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5f111d8f-2b28-4bdb-908b-edbb34e70150",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_parameters = {'num_epoch': 50,\n",
    "                       'batches_per_epoch': 100,\n",
    "                       'eval_iters': 100,\n",
    "                       'quality_metric_iters': 100,\n",
    "                       'learning_rate': 6e-4, # Start lr\n",
    "                       'architecture': f'GPT {million_params:.1f}M',\n",
    "                       'grammar': cfg.__str__(),\n",
    "                       'batch_size':config.batch_size,}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d352a020-b5cf-4996-9d4a-f9af56be809a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "# 1 epoch (train + val is 1m20s)\n",
    "def train(m):\n",
    "    print(f'One epoch is {training_parameters[\"batches_per_epoch\"]} steps,' +\n",
    "    f'validation loss is computed at the end of every epoch and quality metric is '+\n",
    "    f'averaged over {training_parameters[\"quality_metric_iters\"]} sentences')\n",
    "    print(f'Will run for {training_parameters[\"num_epoch\"]} epochs')\n",
    "    total_num_iter = training_parameters['num_epoch'] * training_parameters['batches_per_epoch']\n",
    "    for epoch in range(training_parameters['num_epoch']):\n",
    "        train_loss_sum = .0\n",
    "        m.train()\n",
    "        for iter in range(training_parameters['batches_per_epoch']):\n",
    "            # determine and set the learning rate for this iteration\n",
    "            current_global_iter = iter + epoch * training_parameters['batches_per_epoch']\n",
    "            lr = get_lr(current_global_iter, total_num_iter) if decay_lr else max_lr\n",
    "            for param_group in optimizer.param_groups:\n",
    "                param_group['lr'] = lr\n",
    "                \n",
    "            # sample a batch of data\n",
    "            xb, yb = get_batch(config)\n",
    "            # evaluate the loss\n",
    "            optimizer.zero_grad()\n",
    "            logits = m(xb)\n",
    "            loss = nn.functional.cross_entropy(logits.view(-1, logits.size(-1)), yb.view(-1), ignore_index=-1)\n",
    "            train_loss_sum += loss.item()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        # evaluate the loss on newly generated sentences at the end of every epoch\n",
    "        train_loss = train_loss_sum / config.batch_size\n",
    "        val_loss = estimate_loss(m, training_parameters[\"eval_iters\"])\n",
    "        acc, errors = eval_errors(m, training_parameters['quality_metric_iters'], context_length=3)\n",
    "        log_dict = {\"nb sentences seen\": epoch*training_parameters['batches_per_epoch']*config.batch_size,\n",
    "                    \"val_loss\": val_loss,\n",
    "                    \"train_loss\": train_loss,\n",
    "                    \"accuracy\": acc * 100,\n",
    "                    \"learning_rate\": optimizer.param_groups[0][\"lr\"]}\n",
    "        for i,err in enumerate(errors):\n",
    "            log_dict[f'% of correct sentences at level {i}'] = err\n",
    "            \n",
    "        print(log_dict)\n",
    "        wandb.log(log_dict)\n",
    "        #scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "995d5739-902c-4a28-a12c-b06c35a66ff5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "wandb version 0.15.12 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/adrien/CFGProject/wandb/run-20231107_181613-sye985mr</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/aboitrea/CFG/runs/sye985mr' target=\"_blank\">GPT 10.8M temp=0.1</a></strong> to <a href='https://wandb.ai/aboitrea/CFG' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/aboitrea/CFG' target=\"_blank\">https://wandb.ai/aboitrea/CFG</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/aboitrea/CFG/runs/sye985mr' target=\"_blank\">https://wandb.ai/aboitrea/CFG/runs/sye985mr</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One epoch is 100 steps,validation loss is computed at the end of every epoch and quality metric is averaged over 100 sentences\n",
      "Will run for 50 epochs\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'math' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m wandb\u001b[38;5;241m.\u001b[39minit(project\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCFG\u001b[39m\u001b[38;5;124m'\u001b[39m,config\u001b[38;5;241m=\u001b[39mtraining_parameters, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGPT \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmillion_params\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.1f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124mM temp=0.1\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      2\u001b[0m wandb\u001b[38;5;241m.\u001b[39mwatch(m, log\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mm\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m wandb\u001b[38;5;241m.\u001b[39mfinish()\n",
      "Cell \u001b[0;32mIn[12], line 15\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(m)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m \u001b[38;5;28miter\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(training_parameters[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbatches_per_epoch\u001b[39m\u001b[38;5;124m'\u001b[39m]):\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;66;03m# determine and set the learning rate for this iteration\u001b[39;00m\n\u001b[1;32m     14\u001b[0m     current_global_iter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28miter\u001b[39m \u001b[38;5;241m+\u001b[39m epoch \u001b[38;5;241m*\u001b[39m training_parameters[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbatches_per_epoch\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m---> 15\u001b[0m     lr \u001b[38;5;241m=\u001b[39m \u001b[43mget_lr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcurrent_global_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtotal_num_iter\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m decay_lr \u001b[38;5;28;01melse\u001b[39;00m max_lr\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m param_group \u001b[38;5;129;01min\u001b[39;00m optimizer\u001b[38;5;241m.\u001b[39mparam_groups:\n\u001b[1;32m     17\u001b[0m         param_group[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlr\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m lr\n",
      "Cell \u001b[0;32mIn[9], line 2\u001b[0m, in \u001b[0;36mget_lr\u001b[0;34m(i, i_final)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_lr\u001b[39m(i,i_final):\n\u001b[0;32m----> 2\u001b[0m     coeff \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.5\u001b[39m \u001b[38;5;241m*\u001b[39m (\u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[43mmath\u001b[49m\u001b[38;5;241m.\u001b[39mcos(math\u001b[38;5;241m.\u001b[39mpi \u001b[38;5;241m*\u001b[39m i\u001b[38;5;241m/\u001b[39mi_final)) \u001b[38;5;66;03m# decays from 1 to 0 \u001b[39;00m\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m min_lr \u001b[38;5;241m+\u001b[39m coeff \u001b[38;5;241m*\u001b[39m (max_lr \u001b[38;5;241m-\u001b[39m min_lr)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'math' is not defined"
     ]
    }
   ],
   "source": [
    "wandb.init(project='CFG',config=training_parameters, name=f'GPT {million_params:.1f}M temp=0.1')\n",
    "wandb.watch(m, log='all')\n",
    "\n",
    "train(m)\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2157c81-0bb0-405d-b9ac-09e90af2a182",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_lr = 6e-4  # Maximum learning rate\n",
    "min_lr = 1e-6  # Minimum learning rate\n",
    "total_epochs = training_parameters['num_epoch'] # Total number of epochs\n",
    "div_factor = 1e2  # LR max / LR start\n",
    "final_div_factor = 1e3  # LR max / LR end\n",
    "scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
    "    training_parameters['optimizer'],\n",
    "    max_lr=max_lr,\n",
    "    total_steps=total_epochs,\n",
    "    pct_start=0.2,\n",
    "    div_factor=div_factor,\n",
    "    final_div_factor=final_div_factor\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f31afdb-d58b-4ac2-9239-295d44a5588f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
